{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import relevant files and create master data set\n",
    "filename1 = 'train_set_attr_scld.'\n",
    "train_set_attr_scld = genfromtxt(filename1, delimiter=',')\n",
    "\n",
    "filename2 = 'test_set_scld'\n",
    "test_set_scld = genfromtxt(filename2, delimiter=',')\n",
    "\n",
    "train_set_attr_scld = np.append(train_set_attr_scld,test_set_scld, axis=0)\n",
    "\n",
    "# filenameExp is an experiments text file specifying hyperparameters being tested for each algorithm\n",
    "# The remaining lines for each algorithm are for running processes in parallel on a cluster of cores, \n",
    "#  from which they are printed into log files or saved as .png figures.\n",
    "\n",
    "\n",
    "# RANDOM FOREST CLASSIFICATION\n",
    "\n",
    "def RFC(arr, num_trees, max_features, ftrs):\n",
    "    X = arr[:,ftrs]\n",
    "    Y = arr[:,0] \n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsRF.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            num_trees = float(entries[0])\n",
    "            max_features = int(entries[1])\n",
    "            ftr_size = int(entries[2])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[3 + feature]))\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print(RFC(train_set_attr_scld, num_trees, max_features,ftrs))\n",
    "\n",
    "# K-MEANS CLUSTERING\n",
    "def KMeansAlgorithm(arr, n_clusters, n_init, max_iter):\n",
    "    X = arr[:,1:9]\n",
    "    Y = arr[:,0]\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = KMeans(n_clusters=n_clusters,n_init=n_init,max_iter=max_iter)\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsKM.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            num_trees = int(entries[0])\n",
    "            max_features = int(entries[1])\n",
    "            max_iter = int(entries[2])\n",
    "            ftr_size = int(entries[3])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[4 + feature]))\n",
    "\n",
    "print('K-Means Clustering')\n",
    "print(KMeansAlgorithm(train_set_attr_scld, num_trees, max_features, max_iter, ftrs))\n",
    "\n",
    "# T-DISTRIBUTED STOCHASTIC NEIGHBOR EMBEDDING\n",
    "def TSNE_Alg(arr,perplexity,learning_rate,n_iter,ftrs):\n",
    "    n_sne = 3505790\n",
    "    inputData = train_set_attr_scld[:n_sne,ftrs]\n",
    "    tsne = TSNE(perplexity=perplexity, learning_rate = learning_rate, n_iter=n_iter)\n",
    "    tsne_results = tsne.fit_transform(inputData)\n",
    "    X = tsne_results[:n_sne,0]\n",
    "    Y = tsne_results[:n_sne,1]\n",
    "    label = train_set_attr_scld[:n_sne,0]\n",
    "    colors = ['red','blue','green']\n",
    "    fig = plt.figure(figsize=(25,25))\n",
    "    plt.scatter(x,y, c = label, cmap = matplotlib.colors.ListedColormap(colors)) \n",
    "    fig.savefig('output_' + str(int(sys.argv[1])) + '.png')\n",
    "\n",
    "filenameExp = 'experimentsTSNE.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            perplexity = int(entries[0])\n",
    "            lrate = int(entries[1])\n",
    "            n_iter = int(entries[2])\n",
    "            ftr_size = int(entries[3])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[4 + feature]))\n",
    "\n",
    "print('TSNE')\n",
    "TSNE_Alg(train_set_attr_scld, perplexity, lrate, n_iter,ftrs)\n",
    "\n",
    "# K-NEAREST NEIGHBORS\n",
    "def KNN(arr,n_neighbors,ftrs):\n",
    "    X = arr[:,ftrs]\n",
    "    Y = arr[:,0] \n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsKNN.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            n_neighbors = int(entries[0])\n",
    "            ftr_size = int(entries[1])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[2 + feature]))\n",
    "\n",
    "print('KNN')\n",
    "print(KNN(train_set_attr_scld, n_neighbors,ftrs))\n",
    "\n",
    "# GRADIENT TREE BOOSTING\n",
    "def GTB(arr, num_trees, ftrs):\n",
    "    X = arr[:,ftrs]\n",
    "    Y = arr[:,0] \n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = GradientBoostingClassifier(n_estimators=num_trees)\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsGTB.txt'\n",
    "\n",
    "lineNum = 45\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            num_trees = int(entries[0])\n",
    "            ftr_size = int(entries[1])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[2 + feature]))\n",
    "\n",
    "print('Gradient Tree Boosting')\n",
    "print(GTB(train_set_attr_scld,num_trees,ftrs))\n",
    "\n",
    "# EXTRA TREES\n",
    "def ET(arr, num_trees, ftrs):\n",
    "    X = arr[:,ftrs]\n",
    "    Y = arr[:,0] \n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = ExtraTreesClassifier(n_estimators=num_trees, criterion = \"entropy\", max_features = \"log2\")\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsET.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            num_trees = int(entries[0])\n",
    "            ftr_size = int(entries[1])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[2 + feature]))\n",
    "\n",
    "print('Extra Trees')\n",
    "print(ET(train_set_attr_scld,num_trees,ftrs))\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "def LR(arr, Cval, ftrs):\n",
    "    X = arr[:,ftrs]\n",
    "    Y = arr[:,0] \n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = LogisticRegression(penalty = \"l1\", C = Cval, fit_intercept = True)\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsLR.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            Cval = float(entries[0])\n",
    "            ftr_size = int(entries[1])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[2 + feature]))\n",
    "\n",
    "print('Logistic Regression')\n",
    "print(LR(train_set_attr_scld,Cval,ftrs))\n",
    "\n",
    "# SUPPORT VECTOR CLASSIFICATION\n",
    "def SVC(arr, penalty, ftrs):\n",
    "    X = arr[:,ftrs]\n",
    "    Y = arr[:,0] \n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    model = SVC(C = penalty, kernel = \"poly\", degree = 3, gamma = 0.1, coef0 = 10.0)\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    return results.mean()\n",
    "\n",
    "filenameExp = 'experimentsSVC.txt'\n",
    "\n",
    "lineNum = 0\n",
    "\n",
    "with open(filenameExp) as f:\n",
    "    for line in f:\n",
    "        lineNum = lineNum + 1\n",
    "        if(lineNum == int(sys.argv[1])):\n",
    "            entries = line.split(\",\")\n",
    "            penalty = float(entries[0])\n",
    "            ftr_size = int(entries[1])\n",
    "            ftrs = list()\n",
    "            for feature in range(ftr_size):\n",
    "                ftrs.append(int(entries[2 + feature]))\n",
    "\n",
    "print('Support Vector Classifier')\n",
    "print(SVC(train_set_attr_scld,num_trees,ftrs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
